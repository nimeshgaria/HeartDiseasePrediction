{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     63  1  1.1  145  233  1.2  2  150  2.3  3  0  6  0.1\n",
      "0    67  1    4  160  286    0  2  108  1.5  2  3  3    1\n",
      "1    67  1    4  120  229    0  2  129  2.6  2  2  7    1\n",
      "2    37  1    3  130  250    0  0  187  3.5  3  0  3    0\n",
      "3    41  0    2  130  204    0  2  172  1.4  1  0  3    0\n",
      "4    56  1    2  120  236    0  0  178  0.8  1  0  3    0\n",
      "5    62  0    4  140  268    0  2  160  3.6  3  2  3    0\n",
      "6    57  0    4  120  354    0  0  163  0.6  1  0  3    1\n",
      "7    63  1    4  130  254    0  2  147  1.4  2  1  7    0\n",
      "8    53  1    4  140  203    1  2  155  3.1  3  0  7    1\n",
      "9    57  1    4  140  192    0  0  148  0.4  2  0  6    0\n",
      "10   56  0    2  140  294    0  2  153  1.3  2  0  3    0\n",
      "11   56  1    3  130  256    1  2  142  0.6  2  1  6    1\n",
      "12   44  1    2  120  263    0  0  173  0.0  1  0  7    0\n",
      "13   52  1    3  172  199    1  0  162  0.5  1  0  7    0\n",
      "14   57  1    3  150  168    0  0  174  1.6  1  0  3    0\n",
      "15   48  1    2  110  229    0  0  168  1.0  3  0  7    0\n",
      "16   54  1    4  140  239    0  0  160  1.2  1  0  3    0\n",
      "17   48  0    3  130  275    0  0  139  0.2  1  0  3    0\n",
      "18   49  1    2  130  266    0  0  171  0.6  1  0  3    0\n",
      "19   64  1    1  110  211    0  2  144  1.8  2  0  3    1\n",
      "20   58  0    1  150  283    1  2  162  1.0  1  0  3    0\n",
      "21   58  1    2  120  284    0  2  160  1.8  2  0  3    0\n",
      "22   58  1    3  132  224    0  2  173  3.2  1  2  7    0\n",
      "23   60  1    4  130  206    0  2  132  2.4  2  2  7    1\n",
      "24   50  0    3  120  219    0  0  158  1.6  2  0  3    0\n",
      "25   58  0    3  120  340    0  0  172  0.0  1  0  3    0\n",
      "26   66  0    1  150  226    0  0  114  2.6  3  0  3    0\n",
      "27   43  1    4  150  247    0  0  171  1.5  1  0  3    0\n",
      "28   40  1    4  110  167    0  2  114  2.0  2  0  7    1\n",
      "29   69  0    1  140  239    0  0  151  1.8  1  2  3    0\n",
      "..   .. ..  ...  ...  ...  ... ..  ...  ... .. .. ..  ...\n",
      "266  66  1    4  160  228    0  2  138  2.3  1  0  6    0\n",
      "267  46  1    4  140  311    0  0  120  1.8  2  2  7    1\n",
      "268  71  0    4  112  149    0  0  125  1.6  2  0  3    0\n",
      "269  59  1    1  134  204    0  0  162  0.8  1  2  3    0\n",
      "270  64  1    1  170  227    0  2  155  0.6  2  0  7    0\n",
      "271  66  0    3  146  278    0  2  152  0.0  2  1  3    0\n",
      "272  39  0    3  138  220    0  0  152  0.0  2  0  3    0\n",
      "273  57  1    2  154  232    0  2  164  0.0  1  1  3    0\n",
      "274  58  0    4  130  197    0  0  131  0.6  2  0  3    0\n",
      "275  57  1    4  110  335    0  0  143  3.0  2  1  7    1\n",
      "276  47  1    3  130  253    0  0  179  0.0  1  0  3    0\n",
      "277  55  0    4  128  205    0  1  130  2.0  2  1  7    1\n",
      "278  35  1    2  122  192    0  0  174  0.0  1  0  3    0\n",
      "279  61  1    4  148  203    0  0  161  0.0  1  1  7    0\n",
      "280  58  1    4  114  318    0  1  140  4.4  3  3  6    0\n",
      "281  58  0    4  170  225    1  2  146  2.8  2  2  6    1\n",
      "282  56  1    2  130  221    0  2  163  0.0  1  0  7    0\n",
      "283  56  1    2  120  240    0  0  169  0.0  3  0  3    0\n",
      "284  67  1    3  152  212    0  2  150  0.8  2  0  7    0\n",
      "285  55  0    2  132  342    0  0  166  1.2  1  0  3    0\n",
      "286  44  1    4  120  169    0  0  144  2.8  3  0  6    1\n",
      "287  63  1    4  140  187    0  2  144  4.0  1  2  7    1\n",
      "288  63  0    4  124  197    0  0  136  0.0  2  0  3    1\n",
      "289  41  1    2  120  157    0  0  182  0.0  1  0  3    0\n",
      "290  59  1    4  164  176    1  2   90  1.0  2  2  6    0\n",
      "291  57  0    4  140  241    0  0  123  0.2  2  0  7    1\n",
      "292  45  1    1  110  264    0  0  132  1.2  2  0  7    0\n",
      "293  68  1    4  144  193    1  0  141  3.4  2  2  7    0\n",
      "294  57  1    4  130  131    0  0  115  1.2  2  1  7    1\n",
      "295  57  0    2  130  236    0  2  174  0.0  2  1  3    0\n",
      "\n",
      "[296 rows x 13 columns]\n",
      "119\n"
     ]
    }
   ],
   "source": [
    "#import library\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Read csv file\n",
    "\n",
    "df = pd.read_csv(r'D:\\RBL\\rbl dataset.csv')\n",
    "x = df.iloc[:,0:12].values\n",
    "y = df.iloc[:,12].values\n",
    "print(df)\n",
    "\n",
    "#split training testing data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.40, random_state = 0)\n",
    "\n",
    "print(len(x_test))\n",
    "\n",
    "#SVM classifier\n",
    "\n",
    "from sklearn.svm import SVC  \n",
    "svclassifier = SVC(kernel='linear')  \n",
    "svclassifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred = svclassifier.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[74 11]\n",
      " [15 19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85        85\n",
      "           1       0.63      0.56      0.59        34\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       119\n",
      "   macro avg       0.73      0.71      0.72       119\n",
      "weighted avg       0.77      0.78      0.78       119\n",
      "\n",
      "ACCURACY:  0.7815126050420168\n",
      "ERROR:  0.2184873949579832\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "acc=(74+19)/(74+19+11+15)\n",
    "err=(15+11)/(74+19+11+15)\n",
    "\n",
    "print('ACCURACY: ',acc)\n",
    "print('ERROR: ',err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Lenght:  297\n",
      "Dataset Shape:  (297, 13)\n",
      "Dataset:     0   1   2    3    4   5   6    7    8   9   10  11  12\n",
      "0  63   1   1  145  233   1   2  150  2.3   3   0   6   0\n",
      "1  67   1   4  160  286   0   2  108  1.5   2   3   3   1\n",
      "2  67   1   4  120  229   0   2  129  2.6   2   2   7   1\n",
      "3  37   1   3  130  250   0   0  187  3.5   3   0   3   0\n",
      "4  41   0   2  130  204   0   2  172  1.4   1   0   3   0\n",
      "Results Using Gini Index:\n",
      "Predicted values:\n",
      "[1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0.]\n",
      "Confusion Matrix:  [[44 15]\n",
      " [10 21]]\n",
      "Accuracy :  72.22222222222221\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.75      0.78        59\n",
      "         1.0       0.58      0.68      0.63        31\n",
      "\n",
      "   micro avg       0.72      0.72      0.72        90\n",
      "   macro avg       0.70      0.71      0.70        90\n",
      "weighted avg       0.74      0.72      0.73        90\n",
      "\n",
      "Results Using Entropy:\n",
      "Predicted values:\n",
      "[1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0.]\n",
      "Confusion Matrix:  [[44 15]\n",
      " [10 21]]\n",
      "Accuracy :  72.22222222222221\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.75      0.78        59\n",
      "         1.0       0.58      0.68      0.63        31\n",
      "\n",
      "   micro avg       0.72      0.72      0.72        90\n",
      "   macro avg       0.70      0.71      0.70        90\n",
      "weighted avg       0.74      0.72      0.73        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "  \n",
    "# Function importing Dataset \n",
    "def importdata(): \n",
    "    balance_data = pd.read_csv( \n",
    "r'D:\\RBL\\rbl dataset.csv', \n",
    "    sep= ',', header = None) \n",
    "      \n",
    "    # Printing the dataswet shape \n",
    "    print (\"Dataset Lenght: \", len(balance_data)) \n",
    "    print (\"Dataset Shape: \", balance_data.shape) \n",
    "      \n",
    "    # Printing the dataset obseravtions \n",
    "    print (\"Dataset: \",balance_data.head()) \n",
    "    return balance_data \n",
    "  \n",
    "# Function to split the dataset \n",
    "def splitdataset(balance_data): \n",
    "  \n",
    "    # Seperating the target variable \n",
    "    X = balance_data.values[:, 1:5] \n",
    "    Y = balance_data.values[:, 12] \n",
    "  \n",
    "    # Spliting the dataset into train and test \n",
    "    X_train, X_test, y_train, y_test = train_test_split(  \n",
    "    X, Y, test_size = 0.3, random_state = 100) \n",
    "      \n",
    "    return X, Y, X_train, X_test, y_train, y_test \n",
    "      \n",
    "# Function to perform training with giniIndex. \n",
    "def train_using_gini(X_train, X_test, y_train): \n",
    "  \n",
    "    # Creating the classifier object \n",
    "    clf_gini = DecisionTreeClassifier(criterion = \"gini\", \n",
    "            random_state = 100,max_depth=3, min_samples_leaf=5) \n",
    "  \n",
    "    # Performing training \n",
    "    clf_gini.fit(X_train, y_train) \n",
    "    return clf_gini \n",
    "      \n",
    "# Function to perform training with entropy. \n",
    "def tarin_using_entropy(X_train, X_test, y_train): \n",
    "  \n",
    "    # Decision tree with entropy \n",
    "    clf_entropy = DecisionTreeClassifier( \n",
    "            criterion = \"entropy\", random_state = 100, \n",
    "            max_depth = 3, min_samples_leaf = 5) \n",
    "  \n",
    "    # Performing training \n",
    "    clf_entropy.fit(X_train, y_train) \n",
    "    return clf_entropy \n",
    "  \n",
    "  \n",
    "# Function to make predictions \n",
    "def prediction(X_test, clf_object): \n",
    "  \n",
    "    # Predicton on test with giniIndex \n",
    "    y_pred = clf_object.predict(X_test) \n",
    "    print(\"Predicted values:\") \n",
    "    print(y_pred) \n",
    "    return y_pred \n",
    "      \n",
    "# Function to calculate accuracy \n",
    "def cal_accuracy(y_test, y_pred): \n",
    "      \n",
    "    print(\"Confusion Matrix: \", \n",
    "        confusion_matrix(y_test, y_pred)) \n",
    "      \n",
    "    print (\"Accuracy : \", \n",
    "    accuracy_score(y_test,y_pred)*100) \n",
    "      \n",
    "    print(\"Report : \", \n",
    "    classification_report(y_test, y_pred)) \n",
    "  \n",
    "# Driver code \n",
    "def main(): \n",
    "      \n",
    "    # Building Phase \n",
    "    data = importdata() \n",
    "    X, Y, X_train, X_test, y_train, y_test = splitdataset(data) \n",
    "    clf_gini = train_using_gini(X_train, X_test, y_train) \n",
    "    clf_entropy = tarin_using_entropy(X_train, X_test, y_train) \n",
    "      \n",
    "    # Operational Phase \n",
    "    print(\"Results Using Gini Index:\") \n",
    "      \n",
    "    # Prediction using gini \n",
    "    y_pred_gini = prediction(X_test, clf_gini) \n",
    "    cal_accuracy(y_test, y_pred_gini) \n",
    "      \n",
    "    print(\"Results Using Entropy:\") \n",
    "    # Prediction using entropy \n",
    "    y_pred_entropy = prediction(X_test, clf_entropy) \n",
    "    cal_accuracy(y_test, y_pred_entropy) \n",
    "      \n",
    "      \n",
    "# Calling main function \n",
    "if __name__==\"__main__\": \n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
